{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ETL Top1000 Streamers de Twitch de https://twitchtracker.com/channels/ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\xoel\\anaconda3\\lib\\site-packages (4.4.3)\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.5.0-py3-none-any.whl (995 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
      "Installing collected packages: selenium\n",
      "  Attempting uninstall: selenium\n",
      "    Found existing installation: selenium 4.4.3\n",
      "    Uninstalling selenium-4.4.3:\n",
      "      Successfully uninstalled selenium-4.4.3\n",
      "Successfully installed selenium-4.5.0\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\xoel\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: requests in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\xoel\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\xoel\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: websockets in c:\\users\\xoel\\anaconda3\\lib\\site-packages (10.3)\n",
      "Requirement already satisfied: fake_useragent in c:\\users\\xoel\\anaconda3\\lib\\site-packages (0.1.11)\n"
     ]
    }
   ],
   "source": [
    "# Instalacion de librerias\n",
    "#!pip install BeautifulSoup\n",
    "!pip install -U selenium\n",
    "!pip3 install -U webdriver-manager\n",
    "!pip install pandas\n",
    "!pip install websockets\n",
    "!pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRERIAS\n",
    "\n",
    "# Generales\n",
    "import time\n",
    "import requests\n",
    "import urllib.request\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Gestion de datos\n",
    "import pandas as pd\n",
    "\n",
    "# Automatizacion\n",
    "#from bs4 import BeautifulSoup\n",
    "import undetected_chromedriver as uc\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import selenium\n",
    "# WAF and AntiDDoS Bypass # https://github.com/ultrafunkamsterdam/undetected-chromedriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from fake_useragent import UserAgent\n",
    "#from webdriver_manager.chrome import ChromeDriverManage\n",
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pagina ranking con su numerador de pagina\n",
    "\n",
    "#url = 'https://twitchtracker.com/channels/ranking?page=1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('http://www.google.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = webdriver.ChromeOptions()\n",
    "opts.add_argument(f'user-agent={ua.random}')\n",
    "#opts.add_argument('--headless')\n",
    "opts.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "driver = webdriver.Chrome(options=opts)\n",
    "#driver = uc.Chrome(headless = True, options=opts, use_subprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generador del veiculo driver addcion de atributos y parametros\n",
    "#opts = Options()\n",
    "\n",
    "# Seleccionar el driver\n",
    "#driver = webdriver.Chrome('./chromedriver.exe', options=opts)\n",
    "\n",
    "# Maximizador de ventada del navegador web\n",
    "\n",
    "#driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import undetected_chromedriver as uc\n",
    "#from webdriver_manager.chrome import ChromeDriverManager\n",
    "#from selenium import webdriver\n",
    "#from selenium.webdriver.chrome.service import Service\n",
    "#import time\n",
    "#from fake_useragent import UserAgent\n",
    "#ua = UserAgent()\n",
    "\n",
    "#options = webdriver.ChromeOptions()\n",
    "\n",
    "#options.add_argument(f'user-agent={ua.random}')\n",
    "#chrome_path = ChromeDriverManager().install()\n",
    "#chrome_service = Service(chrome_path)\n",
    "#driver = uc.Chrome(headless = True, options=options, service=chrome_service, use_subprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.set_window_position(0, 0)\n",
    "driver.set_window_size(1920, 1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ir a pagina de Twitchtracker.com\n",
    "\n",
    "#driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## E-xtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rankins = driver.find_elements(By.XPATH, '/html/body/div[2]/div[2]/div[2]/table/tbody/tr')\n",
    "#for rank in rankins:\n",
    "#    print(rank.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraccion de datos2 del TOP50 de Twitchtracker\n",
    "\n",
    "# Numero posicion del Stramer\n",
    "#numero = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[1]')\n",
    "# URL de imagen circular del Streamer\n",
    "#imagen = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[2]')\n",
    "# Nombre del Streamer\n",
    "#nombres_streamer = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[3]')\n",
    "# Promedio de viewer\n",
    "#avg_viewers = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[4]')\n",
    "# Tiempo Streameado\n",
    "#time_streamed = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[5]')\n",
    "# Espectadores de todos los tiempos\n",
    "#all_time_peak_viewers = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[6]')\n",
    "# Horas vistas\n",
    "#hours_watched = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[7]')\n",
    "# Posicion en el anking\n",
    "#rank = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[8]')\n",
    "# Seguidores ganados\n",
    "#followers_gained = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[9]')\n",
    "# Total de seguidores\n",
    "#total_followers = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[10]')\n",
    "# Total de viewers\n",
    "#total_views = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[11]')\n",
    "# Raw information\n",
    "#raw_data = driver.find_elements(By.XPATH, '/html/body/div[2]/div[2]/div[2]/table/tbody/tr')\n",
    "\n",
    "#//*[@id=\"channels\"]/tbody/tr[2]/td[1]\n",
    "\n",
    "#//*[@id=\"channels\"]/thead[1]/tr/th[1]\n",
    "\n",
    "\n",
    "#data_results=[]\n",
    "\n",
    "#for item in range(len(rank)):\n",
    "#    temporal_data={\n",
    "#                    #'Numero': numero[item].text,\n",
    "#                    'URL imagen Streamer': imagen[item].get_attribute('innerHTML'),\n",
    "#                    'Nombres Streamers': nombres_streamer[item].text,\n",
    "#                    'AVG viewers': avg_viewers[item].text,\n",
    "#                    'Time Streamed': time_streamed[item].text,\n",
    "#                    'All time peak viewers': all_time_peak_viewers[item].text,\n",
    "#                    'Hours watched': hours_watched[item].text,\n",
    "#                    'Rank': rank[item].text,\n",
    "#                    'Followers gained': followers_gained[item].text,\n",
    "#                    'Total followers': total_followers[item].text,\n",
    "#                    'Total views': total_views[item].text,\n",
    "#                    #'Raw data': raw_data[item].text,\n",
    "#                    }\n",
    "#    data_results.append(temporal_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos datos del TOP50 de Twitchtracker\n",
    "#df_data = pd.DataFrame(data_results)\n",
    "# Pasar datos por pantalla\n",
    "#df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ByPass WAF\n",
    "#driver.get('https://nowsecure.nl/')\n",
    "\n",
    "#print('reset driver')\n",
    "#handler = driver.current_window_handle\n",
    "#driver.service.stop()\n",
    "#time.sleep(6)\n",
    "#driver = webdriver.Chrome(options=opts)\n",
    "#driver.switch_to.window(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://twitchtracker.com/channels/ranking?page=2'\n",
    "#driver.get(url)\n",
    "\n",
    "data_results=[]\n",
    "def extrac_top1000():\n",
    "    #numerador_pagina = 1\n",
    "    #url = 'https://twitchtracker.com/channels/ranking?page=' + str(numerador_pagina)\n",
    "    numerador_pagina = 0\n",
    "    \n",
    "    url = 'https://twitchtracker.com/channels/ranking?page='\n",
    "    #driver.get(url)\n",
    "    \n",
    "    #El numero de range(XX) marca el numerador final de la pagina 20 serian el Top1000\n",
    "    for i in range(20):\n",
    "        # Extraccion de datos2 del TOP50 de Twitchtracker\n",
    "        \n",
    "        #Sleep\n",
    "        #time.sleep(30)\n",
    "        \n",
    "        numerador_pagina = int(numerador_pagina) + 1\n",
    "        \n",
    "        url_pagina = url + str(numerador_pagina)\n",
    "        \n",
    "        driver.get(url_pagina)\n",
    "        time.sleep(30)\n",
    "        \n",
    "        #driver wait por el Xpath\n",
    "        #nombres_streamer = WebDriverWait(driver,60). until(\n",
    "        #    EC.presence_of_element_located((By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[3]'))\n",
    "        #)\n",
    "        \n",
    "        # Numero posicion del Stramer\n",
    "        #numero = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[1]')\n",
    "        # URL de imagen circular del Streamer\n",
    "        #imagen = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[2]')\n",
    "        # Nombre del Streamer\n",
    "        nombres_streamer = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[3]')\n",
    "        # Promedio de viewer\n",
    "        avg_viewers = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[4]')\n",
    "        # Tiempo Streameado\n",
    "        time_streamed = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[5]')\n",
    "        # Espectadores de todos los tiempos\n",
    "        all_time_peak_viewers = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[6]')\n",
    "        # Horas vistas\n",
    "        hours_watched = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[7]')\n",
    "        # Posicion en el anking\n",
    "        rank = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[8]')\n",
    "        # Seguidores ganados\n",
    "        followers_gained = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[9]')\n",
    "        # Total de seguidores\n",
    "        total_followers = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[10]')\n",
    "        # Total de viewers\n",
    "        total_views = driver.find_elements(By.XPATH, '//*[@id=\"channels\"]/tbody/tr/td[11]')\n",
    "        # Raw information\n",
    "        #raw_data = driver.find_elements(By.XPATH, '/html/body/div[2]/div[2]/div[2]/table/tbody/tr')\n",
    "\n",
    "        for item in range(len(rank)):\n",
    "            temporal_data={\n",
    "                            #'Numero': numero[item].text,\n",
    "                            #'URL imagen Streamer': imagen[item].get_attribute('innerHTML'),\n",
    "                            'Nombres Streamers': nombres_streamer[item].text,\n",
    "                            'AVG viewers': avg_viewers[item].text,\n",
    "                            'Time Streamed (hours)': time_streamed[item].text,\n",
    "                            'All time peak viewers': all_time_peak_viewers[item].text,\n",
    "                            'Hours watched': hours_watched[item].text,\n",
    "                            'Rank': rank[item].text,\n",
    "                            'Followers gained': followers_gained[item].text,\n",
    "                            'Total followers': total_followers[item].text,\n",
    "                            'Total views': total_views[item].text,\n",
    "                            #'Raw data': raw_data[item].text,\n",
    "                            }\n",
    "            data_results.append(temporal_data)\n",
    "    \n",
    "extrac_top1000()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos datos del TOP50 de Twitchtracker\n",
    "df_data = pd.DataFrame(data_results)\n",
    "# Pasar datos por pantalla\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## T-ransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar el \\nhours\n",
    "df_data = df_data.replace(to_replace='\\nhours', value='', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasformar datos de K y M \n",
    "\n",
    "# K\n",
    "df_data['Hours watched'] = df_data['Hours watched'].replace(to_replace='K', value='000', regex=True)\n",
    "df_data['Followers gained'] = df_data['Followers gained'].replace(to_replace='K', value='000', regex=True)\n",
    "df_data['Total followers'] = df_data['Total followers'].replace(to_replace='K', value='000', regex=True)\n",
    "df_data['Total views'] = df_data['Total views'].replace(to_replace='K', value='000', regex=True)\n",
    "# M \n",
    "#df_data['Hours watched'] = df_data['Followers gained'].replace(to_replace='K', value='000', regex=True)\n",
    "df_data['Followers gained'] = df_data['Followers gained'].replace(to_replace='M', value='000000', regex=True)\n",
    "df_data['Total followers'] = df_data['Total followers'].replace(to_replace='M', value='000000', regex=True)\n",
    "df_data['Total views'] = df_data['Total views'].replace(to_replace='M', value='000000', regex=True)\n",
    "df_data['Hours watched'] = df_data['Hours watched'].replace(to_replace='M', value='000000', regex=True)\n",
    "\n",
    "# . K\n",
    "#df_data['Hours watched'] = df_data['Followers gained'].replace(to_replace='K', value='000', regex=True)\n",
    "df_data['Followers gained'] = df_data['Followers gained'].replace(to_replace='\\..*K', value='00', regex=True)\n",
    "df_data['Total followers'] = df_data['Total followers'].replace(to_replace='\\..*K', value='00', regex=True)\n",
    "df_data['Total views'] = df_data['Total views'].replace(to_replace='\\..*K', value='00', regex=True)\n",
    "# . M \n",
    "#df_data['Hours watched'] = df_data['Followers gained'].replace(to_replace='K', value='000', regex=True)\n",
    "df_data['Followers gained'] = df_data['Followers gained'].replace(to_replace='\\..*M', value='00000', regex=True)\n",
    "df_data['Total followers'] = df_data['Total followers'].replace(to_replace='\\..*M', value='00000', regex=True)\n",
    "df_data['Total views'] = df_data['Total views'].replace(to_replace='\\..*M', value='00000', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar ,\n",
    "df_data['AVG viewers'] = df_data['AVG viewers'].replace(to_replace=',', value='', regex=True)\n",
    "df_data['All time peak viewers'] = df_data['All time peak viewers'].replace(to_replace=',', value='', regex=True)\n",
    "df_data['Followers gained'] = df_data['Followers gained'].replace(to_replace=',', value='', regex=True)\n",
    "df_data['Total followers'] = df_data['Total followers'].replace(to_replace=',', value='', regex=True)\n",
    "df_data['Total views'] = df_data['Total views'].replace(to_replace=',', value='', regex=True)\n",
    "df_data['Rank'] = df_data['Rank'].replace(to_replace=',', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar .\n",
    "df_data['Followers gained'] = df_data['Followers gained'].replace(to_replace='\\.', value='', regex=True)\n",
    "df_data['Total followers'] = df_data['Total followers'].replace(to_replace='\\.', value='', regex=True)\n",
    "df_data['Total views'] = df_data['Total views'].replace(to_replace='\\.', value='', regex=True)\n",
    "df_data['Hours watched'] = df_data['Hours watched'].replace(to_replace='\\.', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar el simbolo Positivo (+)\n",
    "df_data['Followers gained'] = df_data['Followers gained'].replace(to_replace='\\+', value='', regex=True)\n",
    "df_data['Hours watched'] = df_data['Hours watched'].replace(to_replace='\\+', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data clean\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## L-oad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportacion a CSV\n",
    "now = datetime.now()\n",
    "datos_top1000_streamers = 'datos_top1000_streamers' + str(now.year) + str(now.month) + str(now.day) + str(now.hour) + str(now.minute) + str(now.second)\n",
    "df_data.to_csv(f'./{datos_top1000_streamers}.csv', index=False ,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
